{
 "metadata": {
  "name": "",
  "signature": "sha256:75c9b1a4547cd986fa9385e0822949494278cf5816f5330c4c09aa28301ed329"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "data = pd.read_csv('../inputdata/movie_metadata.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(data.shape)\n",
      "clean_data = data.dropna(axis = 0)\n",
      "print(clean_data.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(5043, 28)\n",
        "(3756, 28)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.hist(clean_data['imdb_score'], bins=25)\n",
      "plt.title(\"Distribution of IMDB score\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_list = ['movie_facebook_likes','director_facebook_likes','cast_total_facebook_likes',\n",
      "          'actor_1_facebook_likes','actor_2_facebook_likes','actor_3_facebook_likes','duration',\n",
      "          'num_critic_for_reviews','num_voted_users','num_user_for_reviews','budget','gross']\n",
      "\n",
      "plt.figure(figsize=(7,10))\n",
      "for i in range(len(x_list)):\n",
      "    plt.subplot(6,2,i+1)\n",
      "    plt.title(x_list[i])\n",
      "    plt.hist(clean_data[x_list[i]],bins=50)\n",
      "    plt.grid(True)\n",
      "plt.tight_layout()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count = pd.DataFrame({'zero count':[0]*len(x_list)},index = x_list)\n",
      "for element in x_list:\n",
      "    count.ix[element,'zero count'] = sum(np.array(clean_data[element])==0)\n",
      "print(count)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                           zero count\n",
        "movie_facebook_likes             1742\n",
        "director_facebook_likes           642\n",
        "cast_total_facebook_likes           1\n",
        "actor_1_facebook_likes              1\n",
        "actor_2_facebook_likes             11\n",
        "actor_3_facebook_likes             27\n",
        "duration                            0\n",
        "num_critic_for_reviews              0\n",
        "num_voted_users                     0\n",
        "num_user_for_reviews                0\n",
        "budget                              0\n",
        "gross                               0\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if \"director_facebook_likes\" in x_list: x_list.remove(\"director_facebook_likes\")\n",
      "if \"movie_facebook_likes\" in x_list: x_list.remove(\"movie_facebook_likes\")\n",
      "    \n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "x_train, x_test, y_train, y_test = train_test_split(clean_data.ix[:,x_list], clean_data['imdb_score'], \n",
      "                                                    test_size=0.25, random_state=0)\n",
      "\n",
      "\n",
      "#from sklearn import tree\n",
      "#clf=tree.DecisionTreeClassifier()\n",
      "#clf.fit(x_train,y_train)\n",
      "#print \"DecisionTree\",clf.score(x_test,y_test)\n",
      "\n",
      "x_corr = np.corrcoef(x_train,rowvar = 0)\n",
      "eigvl, eigvt = np.linalg.eig(x_corr)\n",
      "print(eigvl)\n",
      "\n",
      "plt.imshow(x_corr, interpolation='nearest', cmap=plt.cm.Blues, extent=(0,10,0,10))\n",
      "plt.colorbar()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  3.66077570e+00   2.00850317e+00   1.74599338e-03   9.90605023e-01\n",
        "   9.06620645e-01   8.30022857e-01   2.09246270e-01   5.30054746e-01\n",
        "   4.20291666e-01   4.42133923e-01]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
        "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_eigen = pd.DataFrame({'min eigen':[0]*len(x_list)},index = x_list)\n",
      "for element in x_list:\n",
      "    x_temp = x_train.drop(element,1)\n",
      "    x_corr = np.corrcoef(x_temp,rowvar = 0)\n",
      "    eigvl, eigvt = np.linalg.eig(x_corr)\n",
      "    min_eigen.ix[element,'min eigen'] = min(eigvl)\n",
      "print(min_eigen)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                           min eigen\n",
        "cast_total_facebook_likes   0.209077\n",
        "actor_1_facebook_likes      0.209040\n",
        "actor_2_facebook_likes      0.020589\n",
        "actor_3_facebook_likes      0.009693\n",
        "duration                    0.001747\n",
        "num_critic_for_reviews      0.001747\n",
        "num_voted_users             0.001750\n",
        "num_user_for_reviews        0.001746\n",
        "budget                      0.001746\n",
        "gross                       0.001845\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import PCA\n",
      "\n",
      "pca = PCA(n_components = 10)\n",
      "pca.fit(x_train)\n",
      "print(np.cumsum(pca.explained_variance_ratio_))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.92413948  0.99999978  0.99999999  1.          1.          1.          1.\n",
        "  1.          1.          1.        ]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca = PCA(n_components = 2)\n",
      "pca.fit(x_train)\n",
      "\n",
      "x_train_new = pca.transform(x_train)\n",
      "\n",
      "from sklearn import linear_model\n",
      "import pylab\n",
      "import scipy.stats as stats\n",
      "\n",
      "def plot_model(x,y,model):\n",
      "    print(\"R^2: %f\" % mod.score(x,y))\n",
      "    \n",
      "    y_fitted = model.predict(x)\n",
      "    residual = y - y_fitted\n",
      "\n",
      "    plt.figure(figsize=(7,5))\n",
      "\n",
      "    plt.subplot(221)\n",
      "    plt.scatter(y_fitted, y)\n",
      "    plt.title(\"fitted value vs actual value\")\n",
      "    plt.xlabel(\"fitted value\")\n",
      "    plt.ylabel(\"actual value\")\n",
      "\n",
      "    plt.subplot(222)\n",
      "    plt.hist(residual, bins=50)\n",
      "    plt.title(\"residual histogram\")\n",
      "\n",
      "\n",
      "    plt.subplot(223)\n",
      "    stats.probplot(residual, dist=\"norm\", plot=pylab)\n",
      "\n",
      "\n",
      "    plt.subplot(224)\n",
      "    plt.scatter(y_fitted,residual)\n",
      "    plt.title(\"fitted value vs residual\")\n",
      "    plt.xlabel(\"fitted value\")\n",
      "    plt.ylabel(\"residual\")\n",
      "\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "    \n",
      "    \n",
      "mod = linear_model.LinearRegression()\n",
      "mod.fit(x_train_new, y_train)\n",
      "plot_model(x_train_new,y_train,mod)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "R^2: 0.049084\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if \"cast_total_facebook_likes\" in x_list: x_list.remove(\"cast_total_facebook_likes\")\n",
      "\n",
      "x_train, x_test, y_train, y_test = train_test_split(clean_data.ix[:,x_list], clean_data['imdb_score'], \n",
      "                                                    test_size=0.25, random_state=0)\n",
      "\n",
      "mod = linear_model.LinearRegression()\n",
      "mod.fit(x_train, y_train)\n",
      "\n",
      "plot_model(x_train,y_train,mod)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "R^2: 0.330708\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "\n",
      "def token(text):\n",
      "    return(text.split(\"|\"))\n",
      "\n",
      "cv_kw=CountVectorizer(max_features=50,tokenizer=token )\n",
      "keywords = cv_kw.fit_transform(clean_data[\"plot_keywords\"])\n",
      "keywords_list = [\"kw_\" + i for i in cv_kw.get_feature_names()]\n",
      "\n",
      "cv_ge=CountVectorizer(tokenizer=token )\n",
      "genres = cv_ge.fit_transform(clean_data[\"genres\"])\n",
      "genres_list = [\"genres_\"+ i for i in cv_ge.get_feature_names()]\n",
      "\n",
      "new_clean_data = np.hstack([clean_data.ix[:,x_list],keywords.todense(),genres.todense()])\n",
      "new_coeff_list = x_list+keywords_list+genres_list\n",
      "\n",
      "x_train, x_test, y_train, y_test = train_test_split(new_clean_data, clean_data['imdb_score'], \n",
      "                                                    test_size=0.25, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mod = linear_model.LinearRegression()\n",
      "mod.fit(x_train, y_train)\n",
      "plot_model(x_train,y_train,mod)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "R^2: 0.460332\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_test_fitted = mod.predict(x_test)\n",
      "plt.scatter(y_test_fitted, y_test)\n",
      "plt.title(\"predicted value vs actual value\")\n",
      "plt.xlabel(\"predicted value\")\n",
      "plt.ylabel(\"actual value\")\n",
      "plt.show()\n",
      "\n",
      "print(\"Score: %f\" % mod.score(x_test,y_test))\n",
      "print(\"SSE: %f\" % sum((y_test_fitted-y_test)**2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Score: 0.447439\n",
        "SSE: 596.629326\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_aic = linear_model.LassoLarsIC(criterion='aic')\n",
      "model_aic.fit(x_train, y_train)\n",
      "\n",
      "def plot_ic_criterion(model, name, color):\n",
      "    alpha_ = model.alpha_\n",
      "    alphas_ = model.alphas_\n",
      "    criterion_ = model.criterion_\n",
      "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color,\n",
      "             linewidth=3, label='%s criterion' % name)\n",
      "    plt.axvline(-np.log10(alpha_), color=color, linewidth=3,\n",
      "                label='alpha: %s estimate' % name)\n",
      "    plt.xlabel('-log(alpha)')\n",
      "    plt.ylabel('criterion')\n",
      "    plt.show()\n",
      "\n",
      "plot_ic_criterion(model_aic, 'AIC', 'b')\n",
      "print(model_aic.alpha_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000236207906005\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mod = linear_model.Lasso(alpha = model_aic.alpha_)\n",
      "mod.fit(x_train, y_train)\n",
      "plot_model(x_train,y_train,mod)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "R^2: 0.459959\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_test_fitted = mod.predict(x_test)\n",
      "\n",
      "plt.scatter(y_test_fitted, y_test)\n",
      "plt.title(\"predicted value vs actual value\")\n",
      "plt.xlabel(\"predicted value\")\n",
      "plt.ylabel(\"actual value\")\n",
      "plt.show()\n",
      "\n",
      "print(\"Score: %f\" % mod.score(x_test,y_test))\n",
      "print(\"SSE: %f\" % sum((y_test_fitted-y_test)**2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Score: 0.447798\n",
        "SSE: 596.240940\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coeff_value = pd.DataFrame(list(mod.coef_),index = new_coeff_list)\n",
      "print(sum(coeff_value[0]==0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imdb_score = np.array(clean_data['imdb_score'])\n",
      "percent25 = np.percentile(imdb_score,33)\n",
      "percent75 = np.percentile(imdb_score,67)\n",
      "\n",
      "clean_list = (imdb_score>percent75) + (imdb_score<percent25)\n",
      "classifier_clean_data = new_clean_data[clean_list]\n",
      "classifier_coeff_list = new_coeff_list\n",
      "\n",
      "imdb_level = list(clean_data['imdb_score'][clean_list]>percent75)\n",
      "imdb_level = [int(i) for i in imdb_level]\n",
      "\n",
      "x_train, x_test, y_train, y_test = train_test_split(classifier_clean_data, imdb_level, \n",
      "                                                    test_size=0.25, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix\n",
      "import itertools\n",
      "\n",
      "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
      "\n",
      "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
      "    plt.title(title)\n",
      "    plt.colorbar()\n",
      "    tick_marks = np.arange(len(classes))\n",
      "    plt.xticks(tick_marks, classes, rotation=45)\n",
      "    plt.yticks(tick_marks, classes)\n",
      "\n",
      "    if normalize:\n",
      "        cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis],2)\n",
      "        print(\"Normalized confusion matrix\")\n",
      "    else:\n",
      "        print('Confusion matrix, without normalization')\n",
      "\n",
      "    print(cm)\n",
      "\n",
      "    thresh = cm.max() / 2.\n",
      "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
      "        plt.text(j, i, cm[i, j],\n",
      "                 horizontalalignment=\"center\",\n",
      "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
      "\n",
      "    plt.tight_layout()\n",
      "    plt.ylabel('True label')\n",
      "    plt.xlabel('Predicted label')\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.model_selection import cross_val_score\n",
      "\n",
      "avg_score_list = []\n",
      "for i in range(1,20):\n",
      "    mod = DecisionTreeClassifier(max_depth = i)\n",
      "    scores = cross_val_score(mod, x_train, y_train, cv=20)\n",
      "    avg_score_list.append(np.mean(scores))\n",
      "    \n",
      "plt.plot(range(1,20),avg_score_list,'--',linewidth=3)\n",
      "plt.axvline(avg_score_list.index(max(avg_score_list))+1, linewidth=3)\n",
      "plt.show()\n",
      "\n",
      "print(\"max score reached with depth %d\" % (avg_score_list.index(max(avg_score_list))+1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "max score reached with depth 13\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_test(x,y,model):\n",
      "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y, [i[1] for i in model.predict_proba(x)])\n",
      "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
      "    plt.plot(false_positive_rate, true_positive_rate, \"b\", label='AUC %0.2f' % (roc_auc))\n",
      "    plt.title(\"AUC Curve\")\n",
      "    plt.show()\n",
      "\n",
      "    auc_score = roc_auc_score(y, [i[1] for i in mod.predict_proba(x)])\n",
      "    cm = confusion_matrix(y,mod.predict(x))\n",
      "    plot_confusion_matrix(cm,classes = [\"bad movie\",\"good movie\"],normalize=False)\n",
      "    print(\"AUC Score: %f\" % auc_score)\n",
      "    print(\"Accuracy: %f\" % (sum(mod.predict(x) == y)/float(len(y))))\n",
      "\n",
      "\n",
      "mod = DecisionTreeClassifier(max_depth = 7)\n",
      "mod.fit(x_train,y_train)\n",
      "plot_test(x_test,y_test,mod)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Confusion matrix, without normalization\n",
        "[[260  32]\n",
        " [ 50 231]]\n",
        "AUC Score: 0.875725"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy: 0.856894\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "avg_score_matrix = []\n",
      "for i in range(1,6):\n",
      "    temp_score = []\n",
      "    for j in range(1,11):\n",
      "        mod = GradientBoostingClassifier(n_estimators=j*20, learning_rate=1.0, max_depth = i, random_state=0)\n",
      "        scores = cross_val_score(mod, x_train, y_train, cv=10)\n",
      "        temp_score.append(np.mean(scores))\n",
      "    avg_score_matrix.append(temp_score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.imshow(np.matrix(avg_score_matrix), interpolation='nearest', cmap=plt.cm.Blues, aspect='auto', extent=(0,200,5,0))\n",
      "plt.ylabel(\"depth\")\n",
      "plt.xlabel(\"tree number\")\n",
      "plt.colorbar()\n",
      "plt.show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "score_matrix = np.matrix(avg_score_matrix)\n",
      "i,j = np.unravel_index(score_matrix.argmax(), score_matrix.shape)\n",
      "print(i,j)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mod = GradientBoostingClassifier(n_estimators=80, learning_rate=1.0, max_depth=1, random_state=0)\n",
      "mod.fit(x_train,y_train)\n",
      "plot_test(x_test,y_test,mod)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Confusion matrix, without normalization\n",
        "[[259  33]\n",
        " [ 30 251]]\n",
        "AUC Score: 0.961555"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy: 0.890052\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "\n",
      "avg_score_matrix = []\n",
      "for i in range(1,2):\n",
      "    temp_score = []\n",
      "    for j in range(1,11):\n",
      "        mod = AdaBoostClassifier(n_estimators=j*20)\n",
      "        scores = cross_val_score(mod, x_train, y_train, cv=10)\n",
      "        temp_score.append(np.mean(scores))\n",
      "    avg_score_matrix.append(temp_score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avg_score_list = []\n",
      "for i in range(1,11):\n",
      "    mod = AdaBoostClassifier(n_estimators=i*20)\n",
      "    scores = cross_val_score(mod, x_train, y_train, cv=10)\n",
      "    avg_score_list.append(np.mean(scores))\n",
      "    \n",
      "plt.plot(range(1,11),avg_score_list,'--',linewidth=3)\n",
      "plt.axvline(avg_score_list.index(max(avg_score_list))+1, linewidth=3)\n",
      "plt.show()\n",
      "\n",
      "print(\"max score reached with depth %d\" % (avg_score_list.index(max(avg_score_list))+1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "max score reached with depth 6\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mod = AdaBoostClassifier(n_estimators=120)\n",
      "mod.fit(x_train,y_train)\n",
      "plot_test(x_test,y_test,mod)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Confusion matrix, without normalization\n",
        "[[262  30]\n",
        " [ 34 247]]\n",
        "AUC Score: 0.958148"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy: 0.888307"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}